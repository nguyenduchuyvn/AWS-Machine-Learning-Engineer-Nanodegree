{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e171c206",
   "metadata": {},
   "source": [
    "# Capstone Project Proposal: Feedback Prize - English Language Learning\n",
    "\n",
    "\n",
    "## Udacity Machine Learning Engineer Nanodegree\n",
    "- Author: NGUYEN DUC HUY\n",
    "- Project from the Kaggle competition: [Feedback Prize - English Language Learning](https://www.kaggle.com/competitions/feedback-prize-english-language-learning)\n",
    "- Field: Natural Language Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4998c6",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "From [Kaggle competition page](https://www.kaggle.com/competitions/feedback-prize-english-language-learning) :\n",
    "\n",
    "Writing is a foundational skill. Sadly, it's one few students are able to hone, often because writing tasks are infrequently assigned in school. A rapidly growing student population, students learning English as a second language, known as English Language Learners (ELLs), are especially affected by the lack of practice. While automated feedback tools make it easier for teachers to assign more writing tasks, they are not designed with ELLs in mind.\n",
    "\n",
    "Existing tools are unable to provide feedback based on the language proficiency of the student, resulting in a final evaluation that may be skewed against the learner. Data science may be able to improve automated feedback tools to better support the unique needs of these learners.\n",
    "\n",
    "Competition host Vanderbilt University is a private research university in Nashville, Tennessee. It offers 70 undergraduate majors and a full range of graduate and professional degrees across 10 schools and colleges, all on a beautiful campus—an accredited arboretum—complete with athletic facilities and state-of-the-art laboratories. Vanderbilt is optimized to inspire and nurture cross-disciplinary research that fosters discoveries that have global impact. Vanderbilt and co-host, The Learning Agency Lab, an independent nonprofit based in Arizona, are focused on developing science of learning-based tools and programs for social good.\n",
    "\n",
    "Vanderbilt and The Learning Agency Lab have partnered together to offer data scientists the opportunity to support ELLs using data science skills in machine learning, natural language processing, and educational data analytics. You can improve automated feedback tools for ELLs by sensitizing them to language proficiency. The resulting tools could serve teachers by alleviating the grading burden and support ELLs by ensuring their work is evaluated within the context of their current language level.\n",
    "\n",
    "## Problem Statement \n",
    "\n",
    "From [Kaggle competition page](https://www.kaggle.com/competitions/feedback-prize-english-language-learning):\n",
    "\n",
    "The goal of this competition is to assess the language proficiency of 8th-12th grade English Language Learners (ELLs). Utilizing a dataset of essays written by ELLs will help to develop proficiency models that better supports all students.\n",
    "\n",
    "Your work will help ELLs receive more accurate feedback on their language development and expedite the grading cycle for teachers. These outcomes could enable ELLs to receive more appropriate learning tasks that will help them improve their English language proficiency.\n",
    "\n",
    "## Evaluation Metrics\n",
    "\n",
    "As any other Kaggle competition, submissions will be benchmarked against the test set that are scored using MCRMSE, mean columnwise root mean squared error:\n",
    "\n",
    "$MCRMSE = \\frac{1}{N_{t}} \\sum_{j=1}^{N_{t}} \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}\\left(y_{i j}-\\hat{y}_{i j}\\right)^{2}}$\n",
    "<!-- ![image](MCRMSE.JPG) -->\n",
    "\n",
    "where Nt is the number of scored ground truth target columns, and y and $\n",
    "\\hat{y}$  are the actual and predicted values, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39de954",
   "metadata": {},
   "source": [
    "## Download the Kaggle dataset using the kaggle python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c03cc49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.8/site-packages (23.2.1)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (68.0.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (0.41.0)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting mxnet<2.0.0\n",
      "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting bokeh==2.0.1\n",
      "  Downloading bokeh-2.0.1.tar.gz (8.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.8/site-packages (from bokeh==2.0.1) (6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from bokeh==2.0.1) (2.8.2)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /opt/conda/lib/python3.8/site-packages (from bokeh==2.0.1) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.8/site-packages (from bokeh==2.0.1) (1.24.4)\n",
      "Requirement already satisfied: pillow>=4.0 in /opt/conda/lib/python3.8/site-packages (from bokeh==2.0.1) (10.0.0)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.8/site-packages (from bokeh==2.0.1) (21.0)\n",
      "Requirement already satisfied: tornado>=5 in /opt/conda/lib/python3.8/site-packages (from bokeh==2.0.1) (6.3.2)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4 in /opt/conda/lib/python3.8/site-packages (from bokeh==2.0.1) (4.7.1)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /opt/conda/lib/python3.8/site-packages (from mxnet<2.0.0) (2.31.0)\n",
      "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet<2.0.0)\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from Jinja2>=2.7->bokeh==2.0.1) (2.1.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=16.8->bokeh==2.0.1) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->bokeh==2.0.1) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2023.7.22)\n",
      "Building wheels for collected packages: bokeh\n",
      "  Building wheel for bokeh (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bokeh: filename=bokeh-2.0.1-py3-none-any.whl size=9080020 sha256=7912fca90f2eaa007b709dbdd40662ca44b8412eda823b824ab980678112bd03\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/5c/a3/49a9ae757ea6918039ffeba015622af9453f91d1f7a7b59be6\n",
      "Successfully built bokeh\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: graphviz, mxnet, bokeh\n",
      "  Attempting uninstall: bokeh\n",
      "    Found existing installation: bokeh 3.1.1\n",
      "    Uninstalling bokeh-3.1.1:\n",
      "      Successfully uninstalled bokeh-3.1.1\n",
      "Successfully installed bokeh-2.0.1 graphviz-0.8.4 mxnet-1.9.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U setuptools wheel\n",
    "!pip install -U \"mxnet<2.0.0\" bokeh==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d243b92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.16.tar.gz (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.8/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.8/site-packages (from kaggle) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.8/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from kaggle) (4.62.3)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.8/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.8/site-packages (from kaggle) (2.0.4)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from kaggle) (4.0.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from bleach->kaggle) (21.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.8/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->kaggle) (3.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->bleach->kaggle) (3.0.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.16-py3-none-any.whl size=110685 sha256=12c720e4032b3daaf8e08d3723d902b49c58a152988f26c1e88fd2aaec81ebde\n",
      "  Stored in directory: /root/.cache/pip/wheels/5a/ab/50/e224f599a07faf6d398a8600796012da271b7e5e7f2a3ab2b8\n",
      "Successfully built kaggle\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: kaggle\n",
      "Successfully installed kaggle-1.5.16\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install Kaggle API client\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd9b635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the .kaggle directory and an empty kaggle.json file\n",
    "# !sudo su -\n",
    "!mkdir -p /root/.kaggle\n",
    "!touch /root/.kaggle/kaggle.json\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "# !sudo mkdir /.kaggle\n",
    "# !sudo cp kaggle.json /.kaggle\n",
    "# !sudo chmod 600 /.kaggle/kaggle.json\n",
    "# !sudo chown `whoami`: /.kaggle/kaggle.json\n",
    "\n",
    "# !export KAGGLE_CONFIG_DIR='/.kaggle/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c52ac0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill in your user name and key from creating the kaggle account and API token file\n",
    "import json\n",
    "kaggle_username = \"duchuy26\"\n",
    "kaggle_key = \"596740039aa231678e0d91b2c54400aa\"\n",
    "\n",
    "# Save API token the kaggle.json file\n",
    "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
    "    f.write(json.dumps({\"username\": kaggle_username, \"key\": kaggle_key}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9dc9327",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading feedback-prize-english-language-learning.zip to /root\n",
      "  0%|                                               | 0.00/2.80M [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 2.80M/2.80M [00:00<00:00, 23.5MB/s]\n",
      "Archive:  feedback-prize-english-language-learning.zip\n",
      "  inflating: sample_submission.csv   \n",
      "  inflating: test.csv                \n",
      "  inflating: train.csv               \n"
     ]
    }
   ],
   "source": [
    "# Download the dataset, it will be in a .zip file so you'll need to unzip it as well.\n",
    "!kaggle competitions download -c feedback-prize-english-language-learning\n",
    "# If you already downloaded it you can use the -o command to overwrite the file\n",
    "!unzip -o feedback-prize-english-language-learning.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c26bac",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d350cef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69bd2541",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  \n",
       "4     3.0         3.0          3.0      2.5          2.5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ### loading traning and test data\n",
    "df_train = pd.read_csv('./train.csv')\n",
    "df_test = pd.read_csv('./test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e4b06db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3911 entries, 0 to 3910\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   text_id      3911 non-null   object \n",
      " 1   full_text    3911 non-null   object \n",
      " 2   cohesion     3911 non-null   float64\n",
      " 3   syntax       3911 non-null   float64\n",
      " 4   vocabulary   3911 non-null   float64\n",
      " 5   phraseology  3911 non-null   float64\n",
      " 6   grammar      3911 non-null   float64\n",
      " 7   conventions  3911 non-null   float64\n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 244.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b2271fb-b3f4-4f88-9814-c60eaa8852f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_id        0\n",
       "full_text      0\n",
       "cohesion       0\n",
       "syntax         0\n",
       "vocabulary     0\n",
       "phraseology    0\n",
       "grammar        0\n",
       "conventions    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6eb1867-eff9-4414-b1fa-152019afde2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('white')\n",
    "sns.despine()\n",
    "fig,ax =plt.subplots(nrows=2,ncols=3,figsize=(10,8))\n",
    "sns.countplot(data=df_train, x='cohesion',ax=ax[0][0])\n",
    "sns.countplot(data=df_train, x='syntax',ax=ax[0][1])\n",
    "sns.countplot(data=df_train, x='vocabulary',ax =ax[0][2])\n",
    "sns.countplot(data=df_train, x='phraseology',ax = ax[1][0])\n",
    "sns.countplot(data=df_train, x='grammar',ax=ax[1][1])\n",
    "sns.countplot(data=df_train, x='conventions',ax=ax[1][2])\n",
    "\n",
    "plt.savefig('count_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad129f11-2761-4169-a145-b2527016b7b7",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "- Scores of the students are completely normally distributed\n",
    "- Ideal range is 2.0-4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "814e4c65-e814-4400-9e57-ae8cd656b83b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df_train.corr(),annot=True,center=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e0b7e-ab85-41ca-8464-2bd69901cbca",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "- There are positive correlation between 'cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12e2b1de-f65b-4db4-b12c-dfbc5b06024d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ATTRS = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, attr in enumerate(ATTRS):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.boxplot(x=df_train[attr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de86056-86ac-4039-b647-4618057c7956",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- cohesion,syntax,phraseology,grammar,conventions doesn't have outliers\n",
    "- There are some outliers in vocabularyneeds to check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f32068e-5aea-4da5-9b05-16e4b480fa50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430.4929685502429\n"
     ]
    }
   ],
   "source": [
    "## total words\n",
    "total_words = []\n",
    "for i in df_train['full_text']:\n",
    "  i = i.split()\n",
    "  total_words.append(len(i))\n",
    "\n",
    "df_train['total_words'] = total_words\n",
    "print(df_train[\"total_words\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94b1a219-f3c8-42c2-87c0-ac9f2eb78cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.histplot(data=df_train, x='total_words')\n",
    "plt.title(\"Distribution of total words\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa093c-db60-4446-96f8-9649b594f344",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- Total words have skewed distribution that occurs when one tail is longer than the other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b62a29-fa2a-49f6-bed3-9846f52d712f",
   "metadata": {},
   "source": [
    "## Algorithms and Techniques\n",
    "\n",
    "In this competition, the learning problem is multi-output regression, where the number of output variables is 6 (as the score for each analytic measures: cohesion, syntax ,vocabulary , phraseology, grammar, conventions), and the input is text.\n",
    "\n",
    "Existing methods for multi-output regression can be categorized as follows:\n",
    "\n",
    "a. Problem transformation methods (also known as local methods) that transform the multi-output problem into independent single-output problems, each solved using a single-output regression algorithm.\n",
    "\n",
    "b. Algorithm adaptation methods that adapt a specific single-output method (such as decision trees and support vector machines) to directly handle multi-output datasets. Algorithm adaptation methods are deemed to be more challenging since they not only aim to predict the multiple targets but also to model and interpret the dependencies among these targets.\n",
    "\n",
    "c. The multi-task learning approach is related to the multi-output regression problem, as it also aims to learn multiple related tasks (i.e., outputs) simultaneously.\n",
    "\n",
    "In this project, I will apply the b. algorithm adaptation methods. The text should be preprocessed to be cleaned and transformed into the standard format. In approach b., the \"clean\" text will be embedded into vectors using different techniques, such as TF-IDF, Word2Vec, Transformer-based embedding, etc. The embedding vectors will then be fed into classical ML models (Random Forest, XGBoost, etc.) for regression tasks.\n",
    "\n",
    "There will be different models suitable for regression, and during the Model Building phase, I will have to evaluate the ML algorithms to decide which one to use. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca300ed8-db2d-4968-94a5-516967b6cb7a",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "Submissions to this competition must be made through Notebooks. In order for the \"Submit\" button to be active after a commit, the following conditions must be met:\n",
    "\n",
    "- CPU Notebook <= 9 hours run-time\n",
    "- GPU Notebook <= 9 hours run-time\n",
    "- Internet access disabled\n",
    "- Freely & publicly available external data is allowed, including pre-trained models\n",
    "- Submission file must be named submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2e310-648f-4827-a300-2532738a2e8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f87b74c-3400-4eb4-86f6-c5cfb8ce9bed",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4f245cb-7ae1-4818-a7a5-c4c151dd9d13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Obtaining dependency information for lightgbm from https://files.pythonhosted.org/packages/f6/9d/fae632fd823b407448b9cd2b28288172c040415e2c9ab401cca9e67b4192/lightgbm-4.0.0-py3-none-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading lightgbm-4.0.0-py3-none-manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from lightgbm) (1.24.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from lightgbm) (1.7.1)\n",
      "Collecting numpy (from lightgbm)\n",
      "  Downloading numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightgbm-4.0.0-py3-none-manylinux_2_28_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: numpy, lightgbm\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.22.4 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed lightgbm-4.0.0 numpy-1.22.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a151df5d-5c7f-4525-abac-702ee188d522",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "# For Text pre-processing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, GridSearchCV\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41e0bc8c-0662-491f-9073-a02b50ecb385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    sen = str(sen).lower()\n",
    "    sen = re.sub('\\[.*?\\]', '', sen)\n",
    "    sen = re.sub('https?://\\S+|www\\.\\S+', '', sen)\n",
    "    sen = re.sub('<.*?>+', '', sen)\n",
    "    sen = re.sub('[%s]' % re.escape(string.punctuation), '', sen)\n",
    "    sen = re.sub('\\n', '', sen)\n",
    "    sen = re.sub('\\w*\\d\\w*', '', sen)\n",
    "    return ' '.join(word_tokenize(sen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74becb23-a7a1-4be5-9fa2-481f2aa818c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "631b46e6-4098-4e09-82b7-66eb29657931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train[\"text\"] = df_train[\"full_text\"].apply(preprocess_text)\n",
    "df_test[\"text\"] = df_test[\"full_text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07f5f99a-edef-4737-8f3e-93f65dd22072",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>total_words</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>261</td>\n",
       "      <td>i think that students would benefit from learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>533</td>\n",
       "      <td>when a problem is a change you have to let it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>320</td>\n",
       "      <td>dear principalif u change the school policy of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  total_words  \\\n",
       "0     3.5         3.0          3.0      4.0          3.0          261   \n",
       "1     2.5         3.0          2.0      2.0          2.5          533   \n",
       "2     3.5         3.0          3.0      3.0          2.5          320   \n",
       "\n",
       "                                                text  \n",
       "0  i think that students would benefit from learn...  \n",
       "1  when a problem is a change you have to let it ...  \n",
       "2  dear principalif u change the school policy of...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9f1cbb5-536f-4a7d-8ed4-3653664ba63f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>Do you think students would benefit from being...</td>\n",
       "      <td>do you think students would benefit from being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
       "      <td>thomas jefferson once states that it is wonder...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  \\\n",
       "0  0000C359D63E  when a person has no experience on a job their...   \n",
       "1  000BAD50D026  Do you think students would benefit from being...   \n",
       "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...   \n",
       "\n",
       "                                                text  \n",
       "0  when a person has no experience on a job their...  \n",
       "1  do you think students would benefit from being...  \n",
       "2  thomas jefferson once states that it is wonder...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07729f19-60aa-4576-ab00-c99a85056089",
   "metadata": {},
   "source": [
    "#### Split train, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61b2c6eb-6bd9-4b0f-bb09-bc8d386ad2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df_train['text']\n",
    "Y = df_train.drop(['full_text', 'text_id', \"text\", \"total_words\"], axis = 1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(X,Y, test_size = 0.20, random_state = 521)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e999bc04-fe3b-4424-bcfd-6c0283106ec5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create pipeline \n",
    "At this stage we perform the training on the test data set for the given number of epochs\n",
    "\n",
    "I used a feature extraction technique CountVectorizer() to convert a collection of text documents into a matrix of token counts. It's a way to represent text data numerically, which is necessary for many machine learning algorithms that expect numerical inputs. Each row of the resulting matrix corresponds to a document, and each column corresponds to a unique word (or \"token\") in the entire collection of documents. The value at a particular row and column represents how many times that word appears in the corresponding document.\n",
    "\n",
    "Then I applied Term Frequency-Inverse Document Frequency Transformer TfidfTransformer(). It's another step in the text processing pipeline that follows the CountVectorizer. While the CountVectorizer counts the occurrences of words in documents, the TF-IDF transformation takes it a step further by considering the importance of words in the context of the entire corpus (collection of documents). For more details:\n",
    "\n",
    "- Term Frequency (TF): This measures how often a word appears in a document. It's calculated as the ratio of the number of times a word appears in a document to the total number of words in that document.\n",
    "\n",
    "- Inverse Document Frequency (IDF): This measures the significance of a word in the entire corpus. Words that appear frequently across all documents are considered less informative, so their IDF score is lower. Words that are rare but appear in specific documents are considered more significant, so their IDF score is higher.\n",
    "\n",
    "- TF-IDF: The TF-IDF score of a word in a document is the product of its Term Frequency and Inverse Document Frequency. It gives a higher weight to words that are important in a document but not very common across all documents.\n",
    "\n",
    "Applying the TfidfTransformer after the CountVectorizer normalizes the word counts based on their significance in both the specific document and the entire corpus, resulting in a more informative representation of the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94dbda2-ed1b-43e6-918d-c059e88aa95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('regressor', MultiOutputRegressor(LGBMRegressor(force_row_wise=true)))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f7234-1477-44e2-8e24-f4b857207959",
   "metadata": {},
   "source": [
    "####  Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "244ed872-405d-48b2-b12b-990bdd285b97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 104326\n",
      "[LightGBM] [Info] Number of data points in the train set: 3128, number of used features: 1959\n",
      "[LightGBM] [Info] Start training from score 3.127877\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104326\n",
      "[LightGBM] [Info] Number of data points in the train set: 3128, number of used features: 1959\n",
      "[LightGBM] [Info] Start training from score 3.020460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104326\n",
      "[LightGBM] [Info] Number of data points in the train set: 3128, number of used features: 1959\n",
      "[LightGBM] [Info] Start training from score 3.231937\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104326\n",
      "[LightGBM] [Info] Number of data points in the train set: 3128, number of used features: 1959\n",
      "[LightGBM] [Info] Start training from score 3.113651\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104326\n",
      "[LightGBM] [Info] Number of data points in the train set: 3128, number of used features: 1959\n",
      "[LightGBM] [Info] Start training from score 3.026535\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 104326\n",
      "[LightGBM] [Info] Number of data points in the train set: 3128, number of used features: 1959\n",
      "[LightGBM] [Info] Start training from score 3.075767\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_val)\n",
    "rmse_score = np.sqrt(mean_squared_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "303d3fc0-4c37-4e9f-a93b-962678d69204",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score RMSE : 0.5699398987688052\n"
     ]
    }
   ],
   "source": [
    "print(f'score RMSE : {rmse_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a908789-0ed0-455f-b779-d0658a61b391",
   "metadata": {},
   "source": [
    "#### Refinement \n",
    "\n",
    "I applied `GridSearchCV` for hyperparameter tuning in machine learning. It's a part of the scikit-learn library and is designed to help you systematically find the best combination of hyperparameters for your machine learning model. Hyperparameters are settings that are not learned from the data during training but are set before training and can significantly impact a model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e37a6ec-f1e4-43a5-87fc-ed75b817748b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.124101\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.011990\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.230815\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.106315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.022982\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.069145\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.122502\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.015188\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.225020\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.109313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.024181\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.076539\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.144484\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.036571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.249800\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.123301\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.037770\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.092326\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.127247\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.022173\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.222932\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.112066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.020176\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.070715\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.121055\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.016380\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.231123\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.117259\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.027567\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.070116\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.124101\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.011990\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.230815\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.106315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.022982\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.069145\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.122502\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.015188\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.225020\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.109313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.024181\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.076539\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.144484\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.036571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.249800\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.123301\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.037770\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.092326\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.127247\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.022173\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.222932\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.112066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.020176\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.070715\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.121055\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.016380\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.231123\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.117259\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.027567\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.070116\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.124101\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.011990\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.230815\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.106315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.022982\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.069145\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.122502\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.015188\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.225020\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.109313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.024181\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.076539\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.144484\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.036571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.249800\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.123301\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.037770\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.092326\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.127247\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.022173\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.222932\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.112066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.020176\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.070715\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.121055\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.016380\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.231123\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.117259\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.027567\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.070116\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.124101\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.011990\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.230815\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.106315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.022982\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.069145\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.122502\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.015188\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.225020\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.109313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.024181\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.076539\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.144484\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.036571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.249800\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.123301\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.037770\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.092326\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.127247\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.022173\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.222932\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.112066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.020176\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.070715\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.121055\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.016380\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.231123\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.117259\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.027567\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.070116\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.124101\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.011990\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.230815\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.106315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.022982\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.069145\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.122502\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.015188\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.225020\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.109313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.024181\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.076539\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.144484\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.036571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.249800\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.123301\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.037770\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.092326\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.127247\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.022173\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.222932\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.112066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.020176\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.070715\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.121055\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.016380\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.231123\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.117259\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.027567\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.070116\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.124101\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.011990\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.230815\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.106315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.022982\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.069145\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.122502\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.015188\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.225020\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.109313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.024181\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.076539\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.144484\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.036571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.249800\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.123301\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.037770\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.092326\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.127247\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.022173\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.222932\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.112066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.020176\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.070715\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.121055\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.016380\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.231123\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.117259\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.027567\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.070116\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.124101\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.011990\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.230815\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.106315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.022982\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.069145\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.122502\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.015188\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.225020\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.109313\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.024181\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.076539\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.144484\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.036571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.249800\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.123301\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.037770\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.092326\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.127247\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.022173\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.222932\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.112066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.020176\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.070715\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.121055\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.016380\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.231123\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.117259\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.027567\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.070116\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.124101\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.011990\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.230815\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.106315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.022982\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.069145\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.122502\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.015188\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.225020\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.109313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.024181\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.076539\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.144484\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.036571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.249800\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.123301\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.037770\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.092326\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.127247\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.022173\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.222932\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.112066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.020176\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.070715\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.121055\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.016380\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.231123\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.117259\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.027567\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.070116\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.124101\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.011990\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.230815\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.106315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.022982\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.069145\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.122502\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.015188\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.225020\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.109313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.024181\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.076539\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.144484\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.036571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.249800\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.123301\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.037770\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.092326\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.127247\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.022173\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.222932\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.112066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.020176\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.070715\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.121055\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.016380\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.231123\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.117259\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.282820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.027567\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.070116\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.124101\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.011990\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.230815\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.106315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.022982\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.069145\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.122502\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.015188\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.225020\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.109313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.024181\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.076539\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.144484\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.036571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.249800\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.123301\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.037770\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.092326\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.127247\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.022173\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.222932\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.112066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.020176\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.070715\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.121055\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.016380\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.231123\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.117259\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.027567\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.070116\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.124101\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.011990\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.230815\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.106315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.022982\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.069145\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.122502\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.015188\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.225020\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.109313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.024181\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.076539\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.144484\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.036571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.249800\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.123301\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.037770\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.092326\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.127247\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.022173\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.222932\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.112066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.020176\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.070715\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.121055\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.016380\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.231123\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.117259\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.027567\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.070116\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.124101\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.011990\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.230815\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.106315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.022982\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1718\n",
      "[LightGBM] [Info] Start training from score 3.069145\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.122502\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.015188\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.225020\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.109313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.024181\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1724\n",
      "[LightGBM] [Info] Start training from score 3.076539\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.144484\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.036571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.249800\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.123301\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.037770\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2502, number of used features: 1749\n",
      "[LightGBM] [Info] Start training from score 3.092326\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.127247\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.022173\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.222932\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.112066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.020176\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87993\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1710\n",
      "[LightGBM] [Info] Start training from score 3.070715\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.121055\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.016380\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.231123\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.117259\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.027567\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87654\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503, number of used features: 1709\n",
      "[LightGBM] [Info] Start training from score 3.070116\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104326\n",
      "[LightGBM] [Info] Number of data points in the train set: 3128, number of used features: 1959\n",
      "[LightGBM] [Info] Start training from score 3.127877\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104326\n",
      "[LightGBM] [Info] Number of data points in the train set: 3128, number of used features: 1959\n",
      "[LightGBM] [Info] Start training from score 3.020460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104326\n",
      "[LightGBM] [Info] Number of data points in the train set: 3128, number of used features: 1959\n",
      "[LightGBM] [Info] Start training from score 3.231937\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104326\n",
      "[LightGBM] [Info] Number of data points in the train set: 3128, number of used features: 1959\n",
      "[LightGBM] [Info] Start training from score 3.113651\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104326\n",
      "[LightGBM] [Info] Number of data points in the train set: 3128, number of used features: 1959\n",
      "[LightGBM] [Info] Start training from score 3.026535\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 104326\n",
      "[LightGBM] [Info] Number of data points in the train set: 3128, number of used features: 1959\n",
      "[LightGBM] [Info] Start training from score 3.075767\n",
      "0.5665026683874527\n",
      "ridge best_para {'regressor__estimator__learning_rate': 0.05, 'regressor__estimator__n_estimators': 150}\n",
      "ridge best_score 0.28621591934380264\n"
     ]
    }
   ],
   "source": [
    "gs_LGBMregressor = GridSearchCV(model, param_grid={'regressor__estimator__learning_rate':[0.1, 0.01, 0.05],\n",
    "                                                  'regressor__estimator__n_estimators':[50, 100, 150, 200] }, cv=5)\n",
    "gs_LGBMregressor.fit(x_train, y_train)\n",
    "y_pred = gs_LGBMregressor.predict(x_val)\n",
    "rmse_score = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(rmse_score)\n",
    "print('ridge best_para',  gs_LGBMregressor.best_params_)\n",
    "print('ridge best_score', gs_LGBMregressor.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a5ed95-f0f0-4863-bf9b-f5ce5074f586",
   "metadata": {},
   "source": [
    "#### Show best parameters and best scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61499cf1-d17a-4e37-a61e-4fd10c06d7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_para {'regressor__estimator__learning_rate': 0.05, 'regressor__estimator__n_estimators': 150}\n",
      "best_score 0.28621591934380264\n"
     ]
    }
   ],
   "source": [
    "print('best_para',  gs_LGBMregressor.best_params_)\n",
    "print('best_score', gs_LGBMregressor.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0109b081-e2a9-4e55-863f-5c2fb9ec5f78",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "826cf606-30c1-4325-ba15-fbae6a5b68f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.03257028 3.10542963 3.44820633 2.7960335  2.83123334 3.18644252]\n",
      " [2.87079064 2.64398903 2.91789446 2.54207937 2.69783948 3.00391354]\n",
      " [3.48761858 3.29316167 3.62794707 3.77436161 3.56723037 3.38253742]]\n"
     ]
    }
   ],
   "source": [
    "# # evaluate best model\n",
    "X_test = df_test['text']\n",
    "y_hat = model.predict(X_test)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5862eb7c-7334-40fe-8caf-3b1dfd655296",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>Do you think students would benefit from being...</td>\n",
       "      <td>do you think students would benefit from being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
       "      <td>thomas jefferson once states that it is wonder...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  \\\n",
       "0  0000C359D63E  when a person has no experience on a job their...   \n",
       "1  000BAD50D026  Do you think students would benefit from being...   \n",
       "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...   \n",
       "\n",
       "                                                text  \n",
       "0  when a person has no experience on a job their...  \n",
       "1  do you think students would benefit from being...  \n",
       "2  thomas jefferson once states that it is wonder...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = df_test.copy(deep=True)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "282a53e6-b287-40cb-a89e-d85f6130c5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
      "0  0000C359D63E  3.032570  3.105430    3.448206     2.796033  2.831233   \n",
      "1  000BAD50D026  2.870791  2.643989    2.917894     2.542079  2.697839   \n",
      "2  00367BB2546B  3.487619  3.293162    3.627947     3.774362  3.567230   \n",
      "\n",
      "   conventions  \n",
      "0     3.186443  \n",
      "1     3.003914  \n",
      "2     3.382537  \n"
     ]
    }
   ],
   "source": [
    "submission['cohesion']   = y_hat[:,0]\n",
    "submission['syntax']     = y_hat[:,1]\n",
    "submission['vocabulary'] = y_hat[:,2]\n",
    "submission['phraseology'] = y_hat[:,3]\n",
    "submission['grammar']     = y_hat[:,4]\n",
    "submission['conventions'] = y_hat[:,5]\n",
    "\n",
    "submission.drop(columns=['full_text', 'text'], inplace=True)\n",
    "print(submission.head())\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375eb9f9-eca4-46b3-bc2c-7bf5ebc267e6",
   "metadata": {},
   "source": [
    "## Results & Conclusion\n",
    "\n",
    "### Model Evaluation and Validation\n",
    "I got the best parameters and best scores as follows:\n",
    "``` python\n",
    "best_para {'regressor__estimator__learning_rate': 0.05, 'regressor__estimator__n_estimators': 150}\n",
    "best_score 0.28621591934380264\n",
    "```\n",
    "I then submitted into Kaggle Competition and got the performing model's score is 0.542448 (Private Score) and 0.530654 (Public Score)  \n",
    "### Reflection\n",
    "- Engaging with an NLP challenge has introduced me to a range of techniques, including text tokenization, exploration of diverse embedding methods, ML algorithm and the manipulation of unstructured data.\n",
    "\n",
    "- Simultaneously, participating in a Kaggle competition provides the opportunity to immerse myself in Kaggle's dynamic and knowledgeable community. The abundance of publicly shared kernels and the willingness of individuals to offer assistance render it an invaluable educational asset.\n",
    "\n",
    "### Improvement\n",
    "\n",
    "- The top performing model's score is 0.542448 (Private Score) and 0.530654 (Public Score) above the benchmark model which is a reasonable improvement, however when compared to scores reached by other participants in this Kaggle competition, this score is average instead.\n",
    "\n",
    "Here are some of the things I believe might improve result:\n",
    "\n",
    "- Build an end-to-end model based on Deep Neural Networks. The last layer will have the number of nodes equal to the number of outputs in the problem. There will be different models suitable for regression such as BERT and RoBERTa.\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
